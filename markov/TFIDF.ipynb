{
 "metadata": {
  "name": "",
  "signature": "sha256:397e614c42c03e71e49b30efed4469f1c1435b7d1da56010c38be70fae1f0782"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ny_nepal = open(\"text/ny_nepal.txt\").read()\n",
      "cnn_nepal = open(\"text/cnn_nepal.txt\").read()\n",
      "ny_avenger = open(\"text/ny_avenger.txt\").read()\n",
      "cnn_avenger = open(\"text/cnn_avenger.txt\").read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "str"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "vectorizer = CountVectorizer(stop_words = 'english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = cnn_nepal.split()\n",
      "z = vectorizer.fit(a)\n",
      "z.vocabulary_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "{'effects': 73,\n",
        " 'recovery': 204,\n",
        " 'half': 105,\n",
        " 'took': 257,\n",
        " 'spring': 233,\n",
        " 'port': 187,\n",
        " 'stuck': 241,\n",
        " 'hope': 113,\n",
        " 'data': 56,\n",
        " 'millions': 159,\n",
        " '81': 13,\n",
        " 'buildings': 33,\n",
        " 'tibet': 253,\n",
        " 'energy': 76,\n",
        " 'underneath': 261,\n",
        " 'magnitude': 145,\n",
        " 'pakistan': 175,\n",
        " 'recent': 202,\n",
        " 'lying': 144,\n",
        " 'catastrophe': 37,\n",
        " 'predicted': 191,\n",
        " 'nations': 167,\n",
        " 'eventually': 83,\n",
        " 'homes': 112,\n",
        " 'event': 81,\n",
        " 'matter': 152,\n",
        " 'knew': 130,\n",
        " 'poorest': 184,\n",
        " 'speed': 232,\n",
        " 'struck': 240,\n",
        " 'feet': 92,\n",
        " 'entire': 78,\n",
        " 'kill': 127,\n",
        " 'rise': 210,\n",
        " 'universities': 264,\n",
        " 'saturday': 213,\n",
        " 'civil': 43,\n",
        " 'changes': 41,\n",
        " 'concertina': 50,\n",
        " 'takes': 248,\n",
        " 'giant': 101,\n",
        " 'coming': 48,\n",
        " 'avalanches': 26,\n",
        " 'nearby': 169,\n",
        " 'taking': 249,\n",
        " 'earthquakes': 70,\n",
        " 'seismology': 219,\n",
        " 'basis': 27,\n",
        " 'slips': 229,\n",
        " '000': 0,\n",
        " 'worse': 278,\n",
        " 'damage': 55,\n",
        " 'exists': 85,\n",
        " 'mass': 150,\n",
        " 'northwards': 172,\n",
        " 'stored': 237,\n",
        " 'economy': 72,\n",
        " 'recorded': 203,\n",
        " 'lowest': 143,\n",
        " 'waves': 271,\n",
        " 'months': 162,\n",
        " 'widespread': 274,\n",
        " 'earth': 68,\n",
        " 'focus': 93,\n",
        " '42': 11,\n",
        " 'square': 234,\n",
        " 'landmarks': 135,\n",
        " 'poorly': 185,\n",
        " 'fault': 91,\n",
        " 'raising': 198,\n",
        " 'bigger': 29,\n",
        " 'pent': 177,\n",
        " 'improving': 117,\n",
        " 'gallery': 95,\n",
        " '13': 4,\n",
        " 'survey': 247,\n",
        " 'expensive': 87,\n",
        " 'greater': 102,\n",
        " 'kind': 129,\n",
        " 'seismologists': 218,\n",
        " 'fatalities': 90,\n",
        " 'getting': 100,\n",
        " 'despite': 60,\n",
        " 'retrofitting': 209,\n",
        " 'enormous': 77,\n",
        " 'pattern': 176,\n",
        " 'strong': 239,\n",
        " 'uncoordinated': 260,\n",
        " 'cities': 42,\n",
        " '2010': 7,\n",
        " 'movement': 165,\n",
        " 'generating': 96,\n",
        " 'himalaya': 109,\n",
        " 'times': 255,\n",
        " 'unfortunately': 263,\n",
        " 'location': 141,\n",
        " 'like': 138,\n",
        " 'scene': 215,\n",
        " 'plane': 181,\n",
        " 'seismometers': 220,\n",
        " 'mountain': 163,\n",
        " 'computation': 49,\n",
        " 'squeezing': 235,\n",
        " 'scattered': 214,\n",
        " 'zone': 281,\n",
        " '20': 6,\n",
        " 'nepal': 170,\n",
        " 'big': 28,\n",
        " 'just': 125,\n",
        " 'images': 115,\n",
        " 'matters': 153,\n",
        " 'shaking': 222,\n",
        " 'delicate': 58,\n",
        " 'efforts': 74,\n",
        " 'area': 23,\n",
        " 'areas': 24,\n",
        " 'infrastructure': 123,\n",
        " 'thanks': 250,\n",
        " 'think': 251,\n",
        " 'actually': 15,\n",
        " 'slowly': 230,\n",
        " 'expand': 86,\n",
        " 'geophysicists': 98,\n",
        " 'haiti': 104,\n",
        " 'unexpected': 262,\n",
        " 'dead': 57,\n",
        " 'miles': 157,\n",
        " 'pokhara': 183,\n",
        " 'way': 272,\n",
        " 'monitored': 161,\n",
        " 'tragic': 258,\n",
        " 'quite': 197,\n",
        " 'agencies': 19,\n",
        " 'differences': 64,\n",
        " '100': 2,\n",
        " 'land': 134,\n",
        " 'new': 171,\n",
        " 'weaker': 273,\n",
        " 'afflicted': 18,\n",
        " 'know': 131,\n",
        " 'emerges': 75,\n",
        " 'designed': 59,\n",
        " 'gets': 99,\n",
        " 'latest': 137,\n",
        " '45': 12,\n",
        " 'killed': 128,\n",
        " 'catastrophically': 39,\n",
        " 'match': 151,\n",
        " 'burma': 34,\n",
        " 'known': 132,\n",
        " 'used': 267,\n",
        " 'today': 256,\n",
        " 'notch': 173,\n",
        " 'time': 254,\n",
        " 'comes': 47,\n",
        " 'academic': 14,\n",
        " 'urban': 266,\n",
        " 'measurements': 155,\n",
        " 'previous': 192,\n",
        " 'disaster': 66,\n",
        " 'destroy': 61,\n",
        " 'detailed': 63,\n",
        " 'events': 82,\n",
        " 'everest': 84,\n",
        " 'estimates': 80,\n",
        " 'fast': 89,\n",
        " 'lack': 133,\n",
        " 'make': 148,\n",
        " 'earthquake': 69,\n",
        " '12': 3,\n",
        " 'subcontinent': 244,\n",
        " 'capita': 35,\n",
        " 'bihar': 30,\n",
        " 'meeting': 156,\n",
        " 'poverty': 189,\n",
        " 'geological': 97,\n",
        " 'larger': 136,\n",
        " 'sent': 221,\n",
        " 'share': 223,\n",
        " 'driven': 67,\n",
        " 'strain': 238,\n",
        " 'seen': 217,\n",
        " 'sliding': 227,\n",
        " 'huge': 114,\n",
        " 'ahead': 20,\n",
        " 'constructed': 51,\n",
        " 'size': 225,\n",
        " 'population': 186,\n",
        " 'rapid': 199,\n",
        " 'cnn': 44,\n",
        " 'currently': 54,\n",
        " 'hamper': 106,\n",
        " 'prince': 193,\n",
        " 'catastrophic': 38,\n",
        " 'columbia': 46,\n",
        " 'seconds': 216,\n",
        " 'surface': 246,\n",
        " 'reported': 207,\n",
        " 'powerful': 190,\n",
        " 'million': 158,\n",
        " 'world': 277,\n",
        " 'fallen': 88,\n",
        " 'fortunately': 94,\n",
        " '40': 10,\n",
        " 'quickly': 196,\n",
        " 'himalayas': 110,\n",
        " 'construction': 52,\n",
        " 'intensity': 124,\n",
        " 'withstand': 276,\n",
        " 'rescue': 208,\n",
        " 'direction': 65,\n",
        " 'minutes': 160,\n",
        " 'years': 280,\n",
        " 'adherence': 16,\n",
        " 'improved': 116,\n",
        " 'destructive': 62,\n",
        " 'kathmandu': 126,\n",
        " 'real': 200,\n",
        " 'valley': 269,\n",
        " 'pushed': 194,\n",
        " 'photos': 179,\n",
        " 'year': 279,\n",
        " 'ground': 103,\n",
        " 'live': 140,\n",
        " 'slip': 228,\n",
        " 'broad': 31,\n",
        " 'income': 119,\n",
        " 'moving': 166,\n",
        " 'major': 146,\n",
        " 'line': 139,\n",
        " 'rough': 211,\n",
        " '21': 8,\n",
        " 'inches': 118,\n",
        " '1934': 5,\n",
        " 'estimate': 79,\n",
        " 'advances': 17,\n",
        " 'unusual': 265,\n",
        " 'crushed': 53,\n",
        " 'careful': 36,\n",
        " 'long': 142,\n",
        " 'similarities': 224,\n",
        " 'width': 275,\n",
        " 'india': 121,\n",
        " 'higher': 108,\n",
        " 'makes': 149,\n",
        " 'appears': 21,\n",
        " 'possible': 188,\n",
        " 'approaching': 22,\n",
        " 'studies': 242,\n",
        " 'majority': 147,\n",
        " '350': 9,\n",
        " 'historic': 111,\n",
        " 'near': 168,\n",
        " 'codes': 45,\n",
        " 'quake': 195,\n",
        " 'thought': 252,\n",
        " 'surely': 245,\n",
        " 'spanning': 231,\n",
        " 'people': 178,\n",
        " 'plates': 182,\n",
        " 'au': 25,\n",
        " 'increases': 120,\n",
        " 'number': 174,\n",
        " 'regular': 205,\n",
        " 'steadily': 236,\n",
        " 'running': 212,\n",
        " 'study': 243,\n",
        " 'using': 268,\n",
        " 'infer': 122,\n",
        " 'heights': 107,\n",
        " 'war': 270,\n",
        " '10': 1,\n",
        " 'slid': 226,\n",
        " 'place': 180,\n",
        " 'means': 154,\n",
        " 'building': 32,\n",
        " 'challenges': 40,\n",
        " 'reason': 201,\n",
        " 'echo': 71,\n",
        " 'releasing': 206,\n",
        " 'mountains': 164,\n",
        " 'triggering': 259}"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = (\n",
      "\"The sky is blue\",\n",
      "\"The sun is bright\",\n",
      "\"The sun in the sky is bright\",\n",
      "\"We can see the shining sun, the bright sun\"\n",
      ")\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
      "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
      "print (tfidf_matrix.shape)\n",
      "print(tfidf_matrix.todense())\n",
      "\n",
      "from collections import Counter\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from nltk.corpus import stopwords\n",
      "filtered = [w for w in cnn_nepal.split() if not w in stopwords.words('english')]\n",
      "\n",
      "def stem_tokens(tokens, stemmer):\n",
      "    stemmed = []\n",
      "    for item in tokens:\n",
      "        stemmed.append(stemmer.stem(item))\n",
      "    return stemmed\n",
      "\n",
      "stemmer = PorterStemmer()\n",
      "stemmed = stem_tokens(filtered, stemmer)\n",
      "count = Counter(stemmed)\n",
      "\n",
      "\n",
      "print (count.most_common(3000))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4, 5)\n",
        "[[ 0.78528828  0.          0.          0.6191303   0.        ]\n",
        " [ 0.          0.70710678  0.          0.          0.70710678]\n",
        " [ 0.          0.53256952  0.          0.65782931  0.53256952]\n",
        " [ 0.          0.36626037  0.57381765  0.          0.73252075]]\n",
        "[('earthquak', 8), ('Nepal', 6), ('shake', 6), ('take', 4), ('one', 4), ('area', 4), ('build', 4), ('around', 4), ('spring', 3), ('Kathmandu', 3), ('event', 3), ('struck', 3), ('kill', 3), ('We', 3), ('time', 3), ('major', 3), ('India', 3), (\"Saturday'\", 3), ('larger', 3), ('fault', 3), ('Haiti', 3), ('peopl', 3), ('The', 3), ('half', 2), ('2010,', 2), ('Everest', 2), ('underneath', 2), ('although', 2), ('make', 2), ('matter', 2), ('--', 2), ('earthquake,', 2), ('magnitud', 2), ('speed', 2), ('improv', 2), ('store', 2), ('rapid', 2), ('Nepal.', 2), ('feet', 2), ('Himalaya', 2), ('million', 2), ('entir', 2), ('come', 2), ('despit', 2), ('In', 2), ('studi', 2), ('enough', 2), ('kind', 2), ('slip', 2), ('like', 2), ('area.', 2), ('long', 2), ('mile', 2), ('big', 2), ('per', 2), ('get', 2), ('emerg', 2), ('photo', 2), ('estim', 2), ('catastroph', 2), ('mountain', 2), ('pent-up', 2), ('most.', 2), ('place', 2), ('predict', 2), ('across', 2), ('nation', 1), ('7.9,', 1), ('match', 1), ('code', 1), ('way', 1), ('power', 1), ('destruct', 1), ('afflict', 1), ('war', 1), ('took', 1), ('poverty,', 1), ('actual', 1), ('known', 1), ('quak', 1), ('incom', 1), ('data', 1), ('exists.', 1), ('81', 1), ('trigger', 1), ('economi', 1), ('U.S.', 1), ('Meet', 1), ('uncoordin', 1), ('advanc', 1), ('disast', 1), ('recoveri', 1), ('2,000', 1), ('Pokhara', 1), ('destroy', 1), ('About', 1), ('adher', 1), ('Tibet', 1), ('100,000', 1), ('citi', 1), ('recent', 1), ('share', 1), ('Imag', 1), ('seconds.', 1), ('fast', 1), ('capita', 1), ('lack', 1), ('mean', 1), ('due', 1), ('hope', 1), ('basi', 1), ('home', 1), ('12', 1), ('knew', 1), ('1.8', 1), ('part', 1), ('lie', 1), ('call', 1), ('poorest', 1), ('quickly.', 1), ('GALLERi', 1), ('care', 1), ('people.', 1), ('To', 1), ('possibl', 1), ('rais', 1), ('world.', 1), ('focu', 1), ('driven', 1), ('Think', 1), ('sure', 1), ('rise', 1), ('gener', 1), ('beyond', 1), ('chang', 1), ('huge', 1), ('record', 1), ('agenc', 1), ('appear', 1), ('pattern', 1), ('21,000', 1), ('sever', 1), ('broad,', 1), ('sinc', 1), ('other.', 1), ('releas', 1), ('height', 1), ('Earth', 1), ('catastrophically,', 1), ('infer', 1), ('neither', 1), ('design', 1), ('Pakistan', 1), ('giant', 1), ('well', 1), ('rescu', 1), ('magnitude-8', 1), ('sent', 1), ('notch', 1), ('steadily.', 1), ('inch', 1), ('world', 1), ('Geophysicist', 1), (\"Nepal'\", 1), ('construction,', 1), ('measur', 1), ('damage.', 1), ('1,000', 1), ('mass', 1), ('Your', 1), ('thank', 1), ('civil', 1), ('almost', 1), ('Port-au-Princ', 1), ('crush', 1), ('new', 1), ('1.45', 1), ('widespread', 1), ('monitor', 1), ('geolog', 1), ('(CNN)In', 1), ('Survey', 1), ('span', 1), ('month', 1), ('quit', 1), ('see', 1), ('computation.', 1), ('current', 1), ('retrofitting,', 1), ('infrastructur', 1), ('7.8', 1), ('histor', 1), ('that:', 1), ('could', 1), ('concertina,', 1), ('energy,', 1), ('previou', 1), ('urban', 1), ('minut', 1), ('intensity).', 1), ('bigger', 1), ('seismologist', 1), ('Burma.', 1), ('real', 1), ('surface.', 1), ('slowli', 1), ('locat', 1), ('valley', 1), ('live', 1), ('Fallen:', 1), ('year', 1), ('42,000', 1), ('13', 1), ('less', 1), ('construct', 1), ('Not', 1), ('$1,350,', 1), ('push', 1), ('Use', 1), ('1934,', 1), ('challeng', 1), ('magnitude-8.1', 1), ('Haiti,', 1), ('delic', 1), ('(a', 1), ('strong', 1), ('popul', 1), ('Studi', 1), ('slide', 1), ('zone', 1), ('slips,', 1), ('similar', 1), ('rough', 1), ('line', 1), ('movement', 1), ('Sometimes,', 1), ('areas,', 1), ('years.', 1), ('1934', 1), (\"Earth'\", 1), ('Unfortunately,', 1), ('Kathmandu,', 1), ('10,000', 1), ('expens', 1), ('would', 1), ('width', 1), ('also', 1), ('fatal', 1), ('years,', 1), ('size', 1), ('higher', 1), ('greater', 1), ('20', 1), ('scatter', 1), ('today.', 1), ('lowest', 1), ('Columbia,', 1), (\"That'\", 1), (\"It'\", 1), ('use', 1), ('approaching,', 1), ('increas', 1), ('energi', 1), ('somehow', 1), ('year.', 1), ('reason', 1), ('surfac', 1), ('moving,', 1), ('(Fortunately,', 1), ('worse,', 1), ('poorli', 1), ('subcontin', 1), ('thought', 1), (\"Saturday's,\", 1), ('eventually.', 1), ('weaker', 1), ('enorm', 1), ('differences,', 1), ('put', 1), ('among', 1), ('A', 1), ('know', 1), ('effort', 1), ('codes.', 1), ('landmark', 1), ('seen', 1), ('number', 1), ('reported.', 1), ('regular', 1), ('Bihar', 1), ('Still,', 1), ('northward', 1), ('Yet', 1), ('univers', 1), ('squar', 1), ('hamper', 1), ('nearbi', 1), ('Avalanch', 1), ('waves.', 1), ('it.', 1), ('scene', 1), ('plate', 1), ('withstand', 1), ('land', 1), ('40%', 1), ('Saturday.', 1), ('10', 1), ('stuck', 1), ('slid', 1), ('after-effects.', 1), ('What', 1), ('dead', 1), ('EXPAND', 1), ('squeez', 1), ('direction,', 1), ('unusu', 1), ('seismomet', 1), ('ground).', 1), ('ahead.', 1), ('tragic', 1), ('detail', 1), ('unexpected,', 1), ('academ', 1), ('long-run', 1), ('latest', 1), ('plane', 1), ('echo', 1), ('Over', 1), ('near', 1), ('Geolog', 1), ('strain', 1), ('seismolog', 1)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.tokenize import RegexpTokenizer\n",
      "a = stopwords.words('english')\n",
      "a.extend(['1','2'])\n",
      "print(a)\n",
      "tokenizer = RegexpTokenizer(r'\\w+')\n",
      "filtered = [w.lower() for w in tokenizer.tokenize(ny_nepal) if not w.lower() in a]\n",
      "stemmed = stem_tokens(filtered, stemmer)\n",
      "count = Counter(stemmed)\n",
      "print (count.most_common(30))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', '1', '2']\n",
        "[('nepal', 20), ('said', 17), ('continu', 17), ('katmandu', 14), ('sunday', 12), ('camp', 11), ('main', 11), ('read', 11), ('rescu', 10), ('earthquak', 10), ('govern', 9), ('countri', 9), ('relief', 8), ('aftershock', 8), ('effort', 8), ('everest', 8), ('avalanch', 7), ('stori', 7), ('2015', 7), ('climber', 7), ('go', 7), ('peopl', 7), ('mount', 6), ('mani', 6), ('capit', 5), ('resid', 5), ('quak', 5), ('alreadi', 5), ('base', 5), ('25', 5)]\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords.words('english').extend(['the','1','2','a'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "['i',\n",
        " 'me',\n",
        " 'my',\n",
        " 'myself',\n",
        " 'we',\n",
        " 'our',\n",
        " 'ours',\n",
        " 'ourselves',\n",
        " 'you',\n",
        " 'your',\n",
        " 'yours',\n",
        " 'yourself',\n",
        " 'yourselves',\n",
        " 'he',\n",
        " 'him',\n",
        " 'his',\n",
        " 'himself',\n",
        " 'she',\n",
        " 'her',\n",
        " 'hers',\n",
        " 'herself',\n",
        " 'it',\n",
        " 'its',\n",
        " 'itself',\n",
        " 'they',\n",
        " 'them',\n",
        " 'their',\n",
        " 'theirs',\n",
        " 'themselves',\n",
        " 'what',\n",
        " 'which',\n",
        " 'who',\n",
        " 'whom',\n",
        " 'this',\n",
        " 'that',\n",
        " 'these',\n",
        " 'those',\n",
        " 'am',\n",
        " 'is',\n",
        " 'are',\n",
        " 'was',\n",
        " 'were',\n",
        " 'be',\n",
        " 'been',\n",
        " 'being',\n",
        " 'have',\n",
        " 'has',\n",
        " 'had',\n",
        " 'having',\n",
        " 'do',\n",
        " 'does',\n",
        " 'did',\n",
        " 'doing',\n",
        " 'a',\n",
        " 'an',\n",
        " 'the',\n",
        " 'and',\n",
        " 'but',\n",
        " 'if',\n",
        " 'or',\n",
        " 'because',\n",
        " 'as',\n",
        " 'until',\n",
        " 'while',\n",
        " 'of',\n",
        " 'at',\n",
        " 'by',\n",
        " 'for',\n",
        " 'with',\n",
        " 'about',\n",
        " 'against',\n",
        " 'between',\n",
        " 'into',\n",
        " 'through',\n",
        " 'during',\n",
        " 'before',\n",
        " 'after',\n",
        " 'above',\n",
        " 'below',\n",
        " 'to',\n",
        " 'from',\n",
        " 'up',\n",
        " 'down',\n",
        " 'in',\n",
        " 'out',\n",
        " 'on',\n",
        " 'off',\n",
        " 'over',\n",
        " 'under',\n",
        " 'again',\n",
        " 'further',\n",
        " 'then',\n",
        " 'once',\n",
        " 'here',\n",
        " 'there',\n",
        " 'when',\n",
        " 'where',\n",
        " 'why',\n",
        " 'how',\n",
        " 'all',\n",
        " 'any',\n",
        " 'both',\n",
        " 'each',\n",
        " 'few',\n",
        " 'more',\n",
        " 'most',\n",
        " 'other',\n",
        " 'some',\n",
        " 'such',\n",
        " 'no',\n",
        " 'nor',\n",
        " 'not',\n",
        " 'only',\n",
        " 'own',\n",
        " 'same',\n",
        " 'so',\n",
        " 'than',\n",
        " 'too',\n",
        " 'very',\n",
        " 's',\n",
        " 't',\n",
        " 'can',\n",
        " 'will',\n",
        " 'just',\n",
        " 'don',\n",
        " 'should',\n",
        " 'now']"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}